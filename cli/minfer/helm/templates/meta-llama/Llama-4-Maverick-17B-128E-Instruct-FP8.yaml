# Description: Template for Llama 4 Maverick 17B 128E Instruct FP8 model deployment with vLLM backend
apiVersion: registry.matrixinfer.ai/v1alpha1
kind: Model
metadata:
  annotations:
    api.kubernetes.io/name: {{ .Values.annotationName | default "example" | quote }}
  name: {{ .Values.name | default "llama-4-maverick-17b-128e-instruct-fp8" | quote }}
  {{- if .Values.namespace }}
  namespace: {{ .Values.namespace | quote }}
  {{- end }}
spec:
  name: {{ .Values.modelName | default .Values.name | default "llama-4-maverick-17b-128e-instruct-fp8" | quote }}
  owner: {{ .Values.owner | default "example" | quote }}
  autoscalingPolicy:
    metrics:
      - metricName: {{ .Values.metricName | default "kthena:num_requests_waiting" | quote }}
        targetValue: {{ .Values.targetValue | default 10 }}
  backends:
    - name: {{ .Values.backendName | default "llama-4-maverick-17b-128e-instruct-fp8-vllm" | quote }}
      type: {{ .Values.backendType | default "vLLM" | quote }}
      modelURI: {{ .Values.modelURI | default "https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8" | quote }}
      cacheURI: {{ .Values.cacheURI | default "hostpath://tmp/test" | quote }}
      minReplicas: {{ .Values.minReplicas | default 1 }}
      maxReplicas: {{ .Values.maxReplicas | default 3 }}
      scalingCost: {{ .Values.scalingCost | default 1 }}
      scaleToZeroGracePeriod: {{ .Values.scaleToZeroGracePeriod | default "60s" | quote }}
      workers:
        - type: {{ .Values.workerType | default "server" | quote }}
          image: {{ .Values.workerImage | default "vllm/vllm-openai:v0.7.1" | quote }}
          replicas: {{ .Values.workerReplicas | default 0 }}
          pods: {{ .Values.workerPods | default 0 }}
          config:
            maxModelLen: {{ .Values.maxModelLen | default 131072 }}
          resources:
            limits:
              nvidia.com/gpu: {{ .Values.gpuLimit | default "1" | quote }}
            requests:
              nvidia.com/gpu: {{ .Values.gpuRequest | default "1" | quote }}
      {{- if .Values.loraAdapters }}
      loraAdapters:
        {{- range .Values.loraAdapters }}
        - name: {{ .name | quote }}
          artifactURL: {{ .artifactURL | quote }}
        {{- end }}
      {{- end }}